# Weekly Reading Group on Offline RL at [GRAIL](https://grail.ift.ulaval.ca/)

**Organizers**: [Mathieu Godbout](mailto:mathieu.godbout.3@ulaval.ca) and [Ulysse Côté-Allard](mailto:ulysseca@uio.no)

## Structure

Everyone reads the weekly paper and a discussion guide is (pseudo-)randomly drawn at beginning of each of our meeting. 
The discussion guide should only drive the conversation and make sure we are able to cover the entirety of the paper within the scheduled hour.
Meetings are every Thursdays from 9AM to 10AM (EST) and occur on [Google Meet](https://meet.google.com/cjz-kyhh-mox).

**This reading group is open to anyone interested. If you wish to join, simply send us [an email](mailto:mathieu.godbout.3@ulaval.ca) so we can add you to our discussion channel.**

## Fall 2021 (part 2)

For this portion of the fall session, we will allow for papers outside of the usual offline RL scope.
Presenters for submitted papers that aren't offline RL related will no longer be randomly sampled, rather being automatically assigned to the person who submitted said paper.

|       Date       | Paper | Presenter |
|:----------------:|:------------------------------------------------------------:|:------------------:|
| 29th October, 2021 | [Pareto Front Identification from Stochastic Bandit Feedback](http://proceedings.mlr.press/v51/auer16)  | Alexandre Larouche |

## Fall 2021

|       Date       | Paper |
|:----------------:|:------------------------------------------------------------:|
|2nd September, 2021 | [Skipped to attend the DEEL workshop on adversarial attack (free registration)](https://www.eventbrite.ca/e/inscription-carrefour-deel-septembre-2021-168642256529) | 
|10th September, 2021 | [Causality and Batch Reinforcement Learning: Complementary Approaches To Planning In Unknown Domains](https://arxiv.org/abs/2006.02579) | 
|17th September, 2021 | [Causal Reinforcement Learning (ICML Tutorial) Part 1&2](https://www.youtube.com/watch?v=QRTgLWfFBMM)| 
|1st October, 2021 | [Efficient Counterfactual Learning from Bandit Feedback](https://arxiv.org/abs/1809.03084)|
|8th October, 2021 | [Improving Long-Term Metrics in Recommendation Systems using Short-Horizon Offline RL](https://arxiv.org/abs/2106.00589) | 
|15th October, 2021 | [A Workflow for Offline Model-Free Robotic Reinforcement Learning](https://arxiv.org/abs/2109.10813) | 
|22th October, 2021 | [Offline Reinforcement Learning with Implicit Q-Learning](https://arxiv.org/abs/2110.06169) | 

## Summer 2021

|       Date       | Paper |
|:----------------:|:------------------------------------------------------------:|
|19th May, 2021 | [Conservative Q-Learning for Offline Reinforcement Learning](https://arxiv.org/abs/2006.04779) | 
|26th May, 2021 | [Offline Reinforcement Learning with Fisher Divergence Critic Regularization](https://arxiv.org/abs/2103.08050) | 
|2nd June, 2021 | [Universal Off-Policy Evaluation](https://arxiv.org/abs/2104.12820) | 
|9th June, 2021 | [What are the Statistical Limits of Offline RL with Linear Function Approximation?](https://arxiv.org/abs/2010.11895) | 
|16th June, 2021 | [An Optimistic Perspective on Offline Reinforcement Learning](https://arxiv.org/abs/1907.04543) | 
|23rd June, 2021 | [Optimism in Reinforcement Learning with Generalized Linear Function Approximation](https://arxiv.org/abs/1912.04136) | 
|30th June, 2021 | [Is Pessimism Provably Efficient for Offline RL?](https://arxiv.org/abs/2012.15085) (The paper is pretty long for a single week's reading. We will base our meeting around [this talk given by the author](https://www.youtube.com/watch?v=vo6HZUDXE1w)) | 
|7th July, 2021 | [Bridging Offline Reinforcement Learning and Imitation Learning: A Tale of Pessimism](https://arxiv.org/abs/2103.12021) ([Talk given by the author](https://www.youtube.com/watch?v=oK0iPImC6KI))| 
|14th July, 2021 | Summer break | 
|21st July, 2021 | Summer break |
|28th July, 2021 | Summer break |
|4th August, 2021 | [S4RL: Surprisingly Simple Self-Supervision for Offline Reinforcement Learning](https://arxiv.org/abs/2103.06326) | 
|11th August, 2021 | [Sample-Efficient Reinforcement Learning via Counterfactual-Based Data Augmentation](https://arxiv.org/abs/2012.09092) | 
|19th August, 2021 | [MOPO: Model-based Offline Policy Optimization](https://arxiv.org/abs/2005.13239) [Second Round]| 
|26th August, 2021 | [Risk-Averse Offline Reinforcement Learning](https://arxiv.org/abs/2102.05371) | 

## Winter 2021

|       Date       | Paper |
|:----------------:|:------------------------------------------------------------:|
|11th March, 2021 | [Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems](https://arxiv.org/abs/2005.01643) (1/4) | 
|18th March, 2021 | [Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems](https://arxiv.org/abs/2005.01643) (2/4) | 
|24th March, 2021 | [Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems](https://arxiv.org/abs/2005.01643) (3/4) | 
|31st March, 2021 | [Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems](https://arxiv.org/abs/2005.01643) (4/4) | 
|7th April, 2021 | [MOPO: Model-based Offline Policy Optimization](https://arxiv.org/abs/2005.13239) | 
