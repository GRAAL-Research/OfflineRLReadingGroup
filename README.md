# Weekly Reading Group on Offline RL at [GRAIL](https://grail.ift.ulaval.ca/)

**Organizers**: [Mathieu Godbout](mailto:mathieu.godbout.3@ulaval.ca) and [Ulysse Côté-Allard](mailto:ulysseca@uio.no)

## Structure

Everyone reads the weekly paper and a discussion guide is (pseudo-)randomly drawn at beginning of each of our meeting. 
The discussion guide should only drive the conversation and make sure we are able to cover the entirety of the paper within the scheduled hour.
Starting from the first of November 2022, meetings are every Tuesday from 9AM to 10AM (EST) and occur on [Zoom](https://meet.google.com/cjz-kyhh-mox).

**This reading group is open to anyone interested. If you wish to join, simply send us [an email](mailto:mathieu.godbout.3@ulaval.ca) so we can add you to our discussion channel.**

## SUMMER 2022

For this semester, we will look a various state of the art reinforcement learning approaches without constraint on their particular domain. The reading group will take the form of a discussion and so no one will be considered the main presentator. 

## Fall 2022
|       Date       | Paper | 
|:----------------:|:------------------------------------------------------------:|
| 1st November, 2022 | [Discovering faster matrix multiplication algorithms with reinforcement learning](https://www.nature.com/articles/s41586-022-05172-4)

## Spring 2022
|       Date       | Paper | 
|:----------------:|:------------------------------------------------------------:|
| 8th April, 2022 | [Why is Posterior Sampling Better than Optimism for Reinforcement Learning](https://arxiv.org/abs/1607.00215)
| 15th April, 2022 | [Collaborating with Humans without Human Data](https://proceedings.neurips.cc/paper/2021/hash/797134c3e42371bb4979a462eb2f042a-Abstract.html)
| 22nd April, 2022 | [Mastering the game of Go without human knowledge](https://www.nature.com/articles/nature24270?sf123103138=1)
| 29th April, 2022 | [AlphaStar: Grandmaster level in StarCraft II using multi-agent reinforcement learning](https://www.nature.com/articles/s41586-019-1724-z?)
| 6th May, 2022 | [GFlowNet](https://www.youtube.com/watch?v=M49TMqK5uCE)
| 13th May, 2022 | [Asymmetric self-play for automatic goal discovery in robotic manipulation](https://arxiv.org/abs/2101.04882)
| 20th May, 2022 | [Continuous multi-task bayesian optimisation with correlation](https://www.sciencedirect.com/science/article/pii/S0377221718302261)
| 27th May, 2022 | [Outracing champion Gran Turismo drivers with deep reinforcement learning](https://www.nature.com/articles/s41586-021-04357-7)
| 3rd June, 2022 | [Planning with Diffusion for Flexible Behavior Synthesis](https://arxiv.org/abs/2205.09991)
| Summer Break | The reading group will start again at the end of July. More details regarding the next paper will be communicated closer to the start date. 

## WINTER 2021-2022

For this semester, we will follow the reinforcement learning class by Emma Brunskill (https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u) at a rythm of one class per week. 

|       Date       | Paper | Presenter |
|:----------------:|:------------------------------------------------------------:|:------------------:|
| 3rd of December, 2021 | [Class 1-2](https://www.youtube.com/watch?v=FgzM3zpZ55o&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=1)  | Introduction & Given a Model of the World |
| 10th December, 2021 | [Class 3](https://www.youtube.com/watch?v=dRIhrn8cc9w&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=3)  | Model-Free Policy Evaluation |
| 17th December, 2021 | [Class 4](https://www.youtube.com/watch?v=j080VBVGkfQ&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=4) | Model Free Control |
| 7th January, 2022 | [Class 5](https://www.youtube.com/watch?v=buptHUzDKcE&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=5) | Value Function Approximation |
| 14th January, 2022 | [Class 6](https://www.youtube.com/watch?v=gOV8-bC1_KU&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=6) | CNNs and Deep Q Learning |
| 7th January, 2022 | [Class 5](https://www.youtube.com/watch?v=buptHUzDKcE&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=5) | Value Function Approximation |
| 21st January, 2022 | [Class 6](https://www.youtube.com/watch?v=gOV8-bC1_KU&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=6) | CNNs and Deep Q Learning |
| 28th January, 2022 | [Class 7](https://www.youtube.com/watch?v=buptHUzDKcE&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=7) | Value Function Approximation |
| 4th February, 2022 | [Class 8](https://www.youtube.com/watch?v=gOV8-bC1_KU&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=8) | Imitation Learning |
| 11th February, 2022 | [Class 9](https://www.youtube.com/watch?v=gOV8-bC1_KU&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=9) | Policy Gradient I |
| 18th February, 2022 | [Class 10](https://www.youtube.com/watch?v=gOV8-bC1_KU&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=10) | Policy Gradient II |
| 25th February, 2022 | [Class 11](https://www.youtube.com/watch?v=gOV8-bC1_KU&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=11) | Policy Gradient III & Review |
| 4th March, 2022 | [Class 12](https://www.youtube.com/watch?v=gOV8-bC1_KU&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=12) | Fast Reinforcement Learning |
| 11th March, 2022 | [Class 13](https://www.youtube.com/watch?v=gOV8-bC1_KU&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=13) | Fast Reinforcement Learning II |
| 18th March, 2022 | [Class 14](https://www.youtube.com/watch?v=gOV8-bC1_KU&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=14) | Fast Reinforcement Learning III |
| 25th March, 2022 | [Class 15](https://www.youtube.com/watch?v=gOV8-bC1_KU&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=15) | Batch Reinforcement Learning |
| 1st April, 2022 | [Class 16](https://www.youtube.com/watch?v=gOV8-bC1_KU&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=16) | Monte Carlo Tree Search |

## Fall 2021 (part 2)

For this portion of the fall session, we will allow for papers outside of the usual offline RL scope.
Presenters for submitted papers that aren't offline RL related will no longer be randomly sampled, rather being automatically assigned to the person who submitted said paper.

|       Date       | Paper | Presenter |
|:----------------:|:------------------------------------------------------------:|:------------------:|
| 29th October, 2021 | [Pareto Front Identification from Stochastic Bandit Feedback](http://proceedings.mlr.press/v51/auer16)  | Alexandre Larouche |
| 5th November, 2021 | [Pessimistic Bootstrapping for Uncertainty-Driven Offline Reinforcement Learning](https://openreview.net/forum?id=Y4cs1Z3HnqL)  | Peng Cheng (Frank) |
| 12th November, 2021 | [COMBO: Conservative Offline Model-Based Policy Optimization](https://arxiv.org/abs/2102.08363) | Random |
| 19th November, 2021 | [Logistic Q-Learning](https://arxiv.org/abs/2010.11151). A 15-minute author presentation is also [available](https://www.youtube.com/watch?v=tZbpA2NKJo0) | Mathieu Godbout |
| 26th November, 2021 | [Believe What You See: Implicit Constraint Approach for Offline Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2106.03400).  Code for the work's implementation [available here](https://github.com/YiqinYang/ICQ) | Ulysse Côté-Allard |

## Fall 2021

|       Date       | Paper |
|:----------------:|:------------------------------------------------------------:|
|2nd September, 2021 | [Skipped to attend the DEEL workshop on adversarial attack (free registration)](https://www.eventbrite.ca/e/inscription-carrefour-deel-septembre-2021-168642256529) | 
|10th September, 2021 | [Causality and Batch Reinforcement Learning: Complementary Approaches To Planning In Unknown Domains](https://arxiv.org/abs/2006.02579) | 
|17th September, 2021 | [Causal Reinforcement Learning (ICML Tutorial) Part 1&2](https://www.youtube.com/watch?v=QRTgLWfFBMM)| 
|1st October, 2021 | [Efficient Counterfactual Learning from Bandit Feedback](https://arxiv.org/abs/1809.03084)|
|8th October, 2021 | [Improving Long-Term Metrics in Recommendation Systems using Short-Horizon Offline RL](https://arxiv.org/abs/2106.00589) | 
|15th October, 2021 | [A Workflow for Offline Model-Free Robotic Reinforcement Learning](https://arxiv.org/abs/2109.10813) | 
|22th October, 2021 | [Offline Reinforcement Learning with Implicit Q-Learning](https://arxiv.org/abs/2110.06169) | 

## Summer 2021

|       Date       | Paper |
|:----------------:|:------------------------------------------------------------:|
|19th May, 2021 | [Conservative Q-Learning for Offline Reinforcement Learning](https://arxiv.org/abs/2006.04779) | 
|26th May, 2021 | [Offline Reinforcement Learning with Fisher Divergence Critic Regularization](https://arxiv.org/abs/2103.08050) | 
|2nd June, 2021 | [Universal Off-Policy Evaluation](https://arxiv.org/abs/2104.12820) | 
|9th June, 2021 | [What are the Statistical Limits of Offline RL with Linear Function Approximation?](https://arxiv.org/abs/2010.11895) | 
|16th June, 2021 | [An Optimistic Perspective on Offline Reinforcement Learning](https://arxiv.org/abs/1907.04543) | 
|23rd June, 2021 | [Optimism in Reinforcement Learning with Generalized Linear Function Approximation](https://arxiv.org/abs/1912.04136) | 
|30th June, 2021 | [Is Pessimism Provably Efficient for Offline RL?](https://arxiv.org/abs/2012.15085) (The paper is pretty long for a single week's reading. We will base our meeting around [this talk given by the author](https://www.youtube.com/watch?v=vo6HZUDXE1w)) | 
|7th July, 2021 | [Bridging Offline Reinforcement Learning and Imitation Learning: A Tale of Pessimism](https://arxiv.org/abs/2103.12021) ([Talk given by the author](https://www.youtube.com/watch?v=oK0iPImC6KI))| 
|14th July, 2021 | Summer break | 
|21st July, 2021 | Summer break |
|28th July, 2021 | Summer break |
|4th August, 2021 | [S4RL: Surprisingly Simple Self-Supervision for Offline Reinforcement Learning](https://arxiv.org/abs/2103.06326) | 
|11th August, 2021 | [Sample-Efficient Reinforcement Learning via Counterfactual-Based Data Augmentation](https://arxiv.org/abs/2012.09092) | 
|19th August, 2021 | [MOPO: Model-based Offline Policy Optimization](https://arxiv.org/abs/2005.13239) [Second Round]| 
|26th August, 2021 | [Risk-Averse Offline Reinforcement Learning](https://arxiv.org/abs/2102.05371) | 

## Winter 2021

|       Date       | Paper |
|:----------------:|:------------------------------------------------------------:|
|11th March, 2021 | [Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems](https://arxiv.org/abs/2005.01643) (1/4) | 
|18th March, 2021 | [Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems](https://arxiv.org/abs/2005.01643) (2/4) | 
|24th March, 2021 | [Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems](https://arxiv.org/abs/2005.01643) (3/4) | 
|31st March, 2021 | [Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems](https://arxiv.org/abs/2005.01643) (4/4) | 
|7th April, 2021 | [MOPO: Model-based Offline Policy Optimization](https://arxiv.org/abs/2005.13239) | 
